{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5a3ab2",
   "metadata": {},
   "source": [
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193d8085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add1172",
   "metadata": {},
   "source": [
    "# Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77842f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Datos:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clientes_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDatos:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m columna \u001b[38;5;129;01min\u001b[39;00m clientes_data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mColumna: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumna\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(clientes_data[columna]\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clientes_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\nDatos:\\n\\n\\n\\n\\n\")\n",
    "for columna in clientes_data.columns:\n",
    "    print(f\"\\nColumna: {columna}\")\n",
    "    print(clientes_data[columna].unique())\n",
    "\n",
    "# Tipos de datos\n",
    "print(\"\\nTipos de datos:\\n\")\n",
    "for col in clientes_data.columns:\n",
    "    print(f\"{col}: {type(clientes_data[col][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b99a6e",
   "metadata": {},
   "source": [
    "## Importar datos, eliminar atributos, convertir formatos atributos, codificar atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeddea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los datos del archivo CSV\n",
    "clientes_data = pd.read_csv('./datos_de_clientes.csv', sep='\\t')\n",
    "\n",
    "# Eliminar las columnas \"Z_CostContact\" y \"Z_Revenue\" ya que contienen el mismo valor para todas las filas, por lo que no aportan información\n",
    "clientes_data = clientes_data.drop(columns=['Z_CostContact', 'Z_Revenue'])\n",
    "\n",
    "# Convertir la columna 'Dt_Customer' a tipo datetime\n",
    "clientes_data['Dt_Customer'] = pd.to_datetime(clientes_data['Dt_Customer'], format='%d-%m-%Y')\n",
    "\n",
    "# Convertir las columnas 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response', 'Complain' a tipo booleano\n",
    "clientes_data[['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response', 'Complain']] = clientes_data[['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response', 'Complain']].astype(bool)\n",
    "\n",
    "\n",
    "#Arregla los datos de estado marital, quitando los valores atipicos \n",
    "# Reemplazar los valores \"YOLO\" y \"Absurd\" por \"Married\"\n",
    "clientes_data['Marital_Status'] = clientes_data['Marital_Status'].replace(['YOLO', 'Absurd'], 'Married')\n",
    "# Reemplazar los valores \"Alone\" por \"Single\"\n",
    "clientes_data['Marital_Status'] = clientes_data['Marital_Status'].replace('Alone', 'Single')\n",
    "\n",
    "# Diccionarios de mapeo para codificación ordinal\n",
    "education_mapping = {'Basic': 1, '2n Cycle': 2, 'Graduation': 3, 'Master': 4, 'PhD': 5}\n",
    "marital_status_mapping = {'Single': 1, 'Widow': 2, 'Divorced': 3, 'Together': 4, 'Married': 5}\n",
    "\n",
    "# Aplicar la codificación ordinal y reemplazar las columnas originales\n",
    "clientes_data['Education'] = clientes_data['Education'].map(education_mapping)\n",
    "clientes_data['Marital_Status'] = clientes_data['Marital_Status'].map(marital_status_mapping)\n",
    "\n",
    "\n",
    "#Revisar si hay espacio vacios\n",
    "# Iterar sobre las filas del DataFrame\n",
    "for index, row in clientes_data.iterrows():\n",
    "    # Verificar si hay un valor nulo en la columna 'ID'\n",
    "    if pd.isnull(row['ID']):\n",
    "        print(\"Hay un espacio vacío en el ID\", index)\n",
    "\n",
    "# Definir la función lambda para codificar las fechas\n",
    "def codificar_fecha(fecha):\n",
    "    if fecha.year < 2013:\n",
    "        return 1\n",
    "    elif fecha.year == 2013:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# Aplicar la función lambda a la columna 'Dt_Customer'\n",
    "clientes_data['Dt_Customer'] = clientes_data['Dt_Customer'].apply(lambda x: codificar_fecha(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349eb8e",
   "metadata": {},
   "source": [
    "## Eliminar datos atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b7ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Iteración 1\n",
      "\n",
      "Número de filas: 214\n",
      "Número de filas con valores atípicos: 0\n",
      "Número de filas después de eliminar los valores atípicos: 214\n",
      "ID                      0\n",
      "Year_Birth              0\n",
      "Education               0\n",
      "Marital_Status          0\n",
      "Income                 17\n",
      "Kidhome                 0\n",
      "Teenhome                0\n",
      "Dt_Customer             0\n",
      "Recency                 0\n",
      "MntWines                0\n",
      "MntFruits               0\n",
      "MntMeatProducts         0\n",
      "MntFishProducts         0\n",
      "MntSweetProducts        0\n",
      "MntGoldProds            0\n",
      "NumDealsPurchases       0\n",
      "NumWebPurchases         0\n",
      "NumCatalogPurchases     0\n",
      "NumStorePurchases       0\n",
      "NumWebVisitsMonth       0\n",
      "AcceptedCmp3            0\n",
      "AcceptedCmp4            0\n",
      "AcceptedCmp5            0\n",
      "AcceptedCmp1            0\n",
      "AcceptedCmp2            0\n",
      "Complain                0\n",
      "Response                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "num_atipicos = 1\n",
    "while num_atipicos > 0:\n",
    "    print(f\"\\n\\nIteración {index}\\n\")\n",
    "    # Imprimir el número de filas\n",
    "    print(\"Número de filas:\", clientes_data.shape[0])\n",
    "    \n",
    "    # Calcular los cuartiles para cada columna\n",
    "    Q1_income = clientes_data['Income'].quantile(0.25)\n",
    "    Q3_income = clientes_data['Income'].quantile(0.75)\n",
    "    IQR_income = Q3_income - Q1_income\n",
    "\n",
    "    Q1_recency = clientes_data['Recency'].quantile(0.25)\n",
    "    Q3_recency = clientes_data['Recency'].quantile(0.75)\n",
    "    IQR_recency = Q3_recency - Q1_recency\n",
    "\n",
    "    # Calcula Q1, Q3 e IQR para las columnas relacionadas con el gasto en productos\n",
    "    columns_mnt = ['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds']\n",
    "    Q1_mnt = clientes_data[columns_mnt].quantile(0.25)\n",
    "    Q3_mnt = clientes_data[columns_mnt].quantile(0.75)\n",
    "    IQR_mnt = Q3_mnt - Q1_mnt\n",
    "\n",
    "    # Calcula Q1, Q3 e IQR para las columnas relacionadas con el número de compras y visitas\n",
    "    columns_purchases_visits = ['NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth']\n",
    "    Q1_purchases_visits = clientes_data[columns_purchases_visits].quantile(0.25)\n",
    "    Q3_purchases_visits = clientes_data[columns_purchases_visits].quantile(0.75)\n",
    "    IQR_purchases_visits = Q3_purchases_visits - Q1_purchases_visits\n",
    "\n",
    "    # Identificar datos atípicos en las columnas seleccionadas\n",
    "    datos_atipicos_income = (clientes_data['Income'] < (Q1_income - 1.5 * IQR_income)) | (clientes_data['Income'] > (Q3_income + 1.5 * IQR_income))\n",
    "    datos_atipicos_recency = (clientes_data['Recency'] < (Q1_recency - 1.5 * IQR_recency)) | (clientes_data['Recency'] > (Q3_recency + 1.5 * IQR_recency))\n",
    "    datos_atipicos_mnt = ((clientes_data[columns_mnt] < (Q1_mnt - 1.5 * IQR_mnt)) | (clientes_data[columns_mnt] > (Q3_mnt + 1.5 * IQR_mnt))).any(axis=1)\n",
    "    datos_atipicos_purchases_visits = ((clientes_data[columns_purchases_visits] < (Q1_purchases_visits - 1.5 * IQR_purchases_visits)) | (clientes_data[columns_purchases_visits] > (Q3_purchases_visits + 1.5 * IQR_purchases_visits))).any(axis=1)\n",
    "\n",
    "    # Combinar los resultados de detección de valores atípicos\n",
    "    datos_atipicos = datos_atipicos_income | datos_atipicos_recency | datos_atipicos_mnt | datos_atipicos_purchases_visits\n",
    "    # Imprimir el número de filas con valores atípicos\n",
    "    print(\"Número de filas con valores atípicos:\", clientes_data[datos_atipicos].shape[0])\n",
    "    num_atipicos = clientes_data[datos_atipicos].shape[0]\n",
    "\n",
    "    # Filtrar el DataFrame original para eliminar las filas con valores atípicos\n",
    "    clientes_data = clientes_data[~datos_atipicos]\n",
    "\n",
    "    # Imprimir el número de filas después de eliminar los valores atípicos\n",
    "    print(\"Número de filas después de eliminar los valores atípicos:\", clientes_data.shape[0])\n",
    "    index += 1\n",
    "\n",
    "# Muestra cuántos valores nulos hay en cada columna\n",
    "print(clientes_data_sin_atipicos.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfadb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
